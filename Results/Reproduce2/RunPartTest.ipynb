{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Ab3IYZuMIqkR",
        "outputId": "07dae3c1-68aa-4fa4-bb66-453c5113c4e3"
      },
      "outputs": [],
      "source": [
        "#Confirms main.py prints s1/s5 lines\n",
        "MAIN = \"/content/content/synth/main.py\"   #change only if your path is different\n",
        "\n",
        "with open(MAIN, \"r\", errors=\"ignore\") as f:\n",
        "    txt = f.read()\n",
        "assert \"s1:\" in txt and \"s5:\" in txt, \"Please apply the s1/s5 patch to main.py first.\"\n",
        "print(\"Yes: main.py has s1/s5 in its progress print.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OGzBmSAKUcL"
      },
      "outputs": [],
      "source": [
        "#paths\n",
        "MAIN   = \"/content/content/synth/main.py\" #keep consistent\n",
        "LOGDIR = \"/content/run_logs_full\" #full-run logs here\n",
        "\n",
        "import os, pathlib, shlex, subprocess\n",
        "pathlib.Path(LOGDIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def run_and_log(tag, **kw):\n",
        "    \"\"\"\n",
        "    Runs main.py with given kwargs and writes stdout to LOGDIR/{tag}.log\n",
        "    \"\"\"\n",
        "    cmd = [\"python\", MAIN]\n",
        "    for k, v in kw.items():\n",
        "        cmd += [f\"--{k}\", str(v)]\n",
        "    print(\"RUN:\", \" \".join(shlex.quote(c) for c in cmd))\n",
        "    out = subprocess.run(cmd, text=True, capture_output=True)\n",
        "    print(out.stdout)\n",
        "    open(f\"{LOGDIR}/{tag}.log\", \"w\").write(out.stdout)\n",
        "    if out.stderr.strip():\n",
        "        print(\"STDERR:\\n\", out.stderr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDK_zo7xKXh0"
      },
      "outputs": [],
      "source": [
        "#Learning rates LR-finder and tests\n",
        "LR_GD   = \"1e-3\"\n",
        "LR_ADAM = \"1e-3\"\n",
        "\n",
        "#Long iteration counts\n",
        "LONG_ITERS_GD   = 800_000\n",
        "LONG_ITERS_ADAM = 30_000\n",
        "\n",
        "#Shared synthetic configuration\n",
        "BASE_SYN = dict(\n",
        "    method=\"DLNN\",\n",
        "    data=\"gaussian\", #noiseless synthetic\n",
        "    N=100, #problem size\n",
        "    rank=5,\n",
        "    reg_norm=\"ratio\",\n",
        "    initscale=\"1e-3\",\n",
        "    sample_size=4000,\n",
        "    log_interval=2000 #fewer log lines -> smaller files\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtisijdIKbcP",
        "outputId": "89853721-804c-4d4d-e03f-ab6e4788c84f"
      },
      "outputs": [],
      "source": [
        "'''for depth in (2, 5):\n",
        "    # GD (solid in plots)\n",
        "    run_and_log(f\"F1_gd_d{depth}_lam0\",\n",
        "        **BASE_SYN, depth=depth, lam=\"0.0\", optim=\"GD\",   lr=LR_GD,   niters=LONG_ITERS_GD)\n",
        "\n",
        "    # Adam (dashed in plots)\n",
        "    run_and_log(f\"F1_adam_d{depth}_lam0\",\n",
        "        **BASE_SYN, depth=depth, lam=\"0.0\", optim=\"Adam\", lr=LR_ADAM, niters=LONG_ITERS_ADAM)\n",
        "        '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "eQfVIvh4Kf9X",
        "outputId": "c4c9f1b3-79eb-4d82-dadd-39379e7447bf"
      },
      "outputs": [],
      "source": [
        "'''for opt, lr, steps in ((\"Adam\", LR_ADAM, LONG_ITERS_ADAM), (\"GD\", LR_GD, LONG_ITERS_GD)):\n",
        "    run_and_log(f\"F2_{opt.lower()}_d3_lam1e-4\",\n",
        "        **BASE_SYN, depth=3, lam=\"1e-4\", optim=opt, lr=lr, niters=steps)\n",
        "        '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEy0qmK0KiKU"
      },
      "outputs": [],
      "source": [
        "for lam in (\"0.0\", \"1e-2\"):\n",
        "    run_and_log(f\"F3_gd_d1_lam{lam}\",\n",
        "        **BASE_SYN, depth=1, lam=lam, optim=\"GD\",   lr=LR_GD,   niters=LONG_ITERS_GD)\n",
        "    run_and_log(f\"F3_adam_d1_lam{lam}\",\n",
        "        **BASE_SYN, depth=1, lam=lam, optim=\"Adam\", lr=LR_ADAM, niters=LONG_ITERS_ADAM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0drBPvOvKkb5"
      },
      "outputs": [],
      "source": [
        "#Fetch ML-100k (safe no-op if present)\n",
        "import os, urllib.request, zipfile, io, pathlib\n",
        "ML_DIR = \"/content/ml-100k\"\n",
        "if not os.path.exists(f\"{ML_DIR}/u.data\"):\n",
        "    print(\"Downloading MovieLens 100k …\")\n",
        "    data = urllib.request.urlopen(\"https://files.grouplens.org/datasets/movielens/ml-100k.zip\").read()\n",
        "    zipfile.ZipFile(io.BytesIO(data)).extractall(\"/content\")\n",
        "    assert os.path.exists(f\"{ML_DIR}/u.data\"), \"MovieLens 100k not found after download.\"\n",
        "print(\"✔ MovieLens ready.\")\n",
        "\n",
        "BASE_ML = dict(\n",
        "    method=\"DLNN\",\n",
        "    data=\"ml-100k-sample\",\n",
        "    depth=1,\n",
        "    optim=\"Adam\",\n",
        "    lr=\"5e-4\", #working LR\n",
        "    trainprop=\"0.8\",\n",
        "    reg_norm=\"ratio\",\n",
        "    initscale=\"1e-3\",\n",
        "    log_interval=1000\n",
        ")\n",
        "\n",
        "#λ = 0 vs 1e-3\n",
        "run_and_log(\"ML_lam0_adam_long\",    **BASE_ML, lam=\"0.0\",  niters=40_000)\n",
        "run_and_log(\"ML_lam1e-3_adam_long\", **BASE_ML, lam=\"1e-3\", niters=40_000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgyW5HQVKn9q"
      },
      "outputs": [],
      "source": [
        "import os, re, glob, pandas as pd, numpy as np\n",
        "\n",
        "LOG_GLOBS = [os.path.join(LOGDIR, \"*.log\")]\n",
        "files = sorted({p for g in LOG_GLOBS for p in glob.glob(g)})\n",
        "\n",
        "pat = re.compile(\n",
        "    r\"depth:\\s*(\\d+).*?iteration:\\s*(\\d+).*?\"\n",
        "    r\"test_RMSE:\\s*([\\-0-9\\.Ee\\+]+).*?erank:\\s*([\\-0-9\\.Ee\\+]+).*?\"\n",
        "    r\"s1:\\s*([\\-0-9\\.Ee\\+]+).*?s5:\\s*([\\-0-9\\.Ee\\+]+)\"\n",
        ")\n",
        "\n",
        "def infer_opt(name):\n",
        "    n = name.lower()\n",
        "    if \"adam\" in n: return \"adam\"\n",
        "    if \"gd\"   in n: return \"gd\"\n",
        "    return \"unk\"\n",
        "\n",
        "rows = []\n",
        "for path in files:\n",
        "    with open(path, \"r\", errors=\"ignore\") as f:\n",
        "        for line in f:\n",
        "            m = pat.search(line)\n",
        "            if not m: continue\n",
        "            d,it,rmse,er,s1,s5 = m.groups()\n",
        "            rows.append(dict(\n",
        "                file=os.path.basename(path),\n",
        "                optimizer=infer_opt(path),\n",
        "                depth=int(d),\n",
        "                iteration=int(it),\n",
        "                test_RMSE=float(rmse),\n",
        "                erank=float(er),\n",
        "                s1=float(s1),\n",
        "                s5=float(s5),\n",
        "            ))\n",
        "\n",
        "df = pd.DataFrame(rows).sort_values([\"optimizer\",\"depth\",\"iteration\"]).reset_index(drop=True)\n",
        "print(f\"Parsed {len(df)} rows from {len(files)} log files.\")\n",
        "if df.empty:\n",
        "    raise RuntimeError(\"No rows parsed – make sure runs completed and s1/s5 are printed.\")\n",
        "df.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDvFpC29KqCi"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_sv_panel(opt_name, title):\n",
        "    sub = df[df[\"optimizer\"]==opt_name]\n",
        "    if sub.empty: return\n",
        "    plt.figure(figsize=(6.2,4.4))\n",
        "    for d in sorted(sub[\"depth\"].unique()):\n",
        "        cur = sub[sub[\"depth\"]==d]\n",
        "        if cur.empty: continue\n",
        "        plt.plot(cur[\"iteration\"], cur[\"s1\"], label=f\"depth={d} (s1)\")\n",
        "        plt.plot(cur[\"iteration\"], cur[\"s5\"], linestyle=\"--\", label=f\"depth={d} (s5)\")\n",
        "    plt.title(title); plt.xlabel(\"iteration\"); plt.ylabel(\"magnitude\")\n",
        "    plt.legend(bbox_to_anchor=(1.02,1), loc=\"upper left\"); plt.tight_layout(); plt.show()\n",
        "\n",
        "plot_sv_panel(\"gd\",   \"GD: singular values\")\n",
        "plot_sv_panel(\"adam\", \"Adam: singular values\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PE1uVKkLKuA4"
      },
      "outputs": [],
      "source": [
        "def plot_metric(metric, title):\n",
        "    plt.figure(figsize=(6.6,4.4))\n",
        "    for opt in (\"gd\",\"adam\"):\n",
        "        for d in sorted(df[\"depth\"].unique()):\n",
        "            cur = df[(df.optimizer==opt) & (df.depth==d)]\n",
        "            if cur.empty: continue\n",
        "            ls = \"-\" if opt==\"gd\" else \"--\"\n",
        "            plt.plot(cur[\"iteration\"], cur[metric], ls, label=f\"{opt.upper()} d={d}\")\n",
        "    plt.xlabel(\"iteration\"); plt.ylabel(metric); plt.title(title)\n",
        "    plt.legend(bbox_to_anchor=(1.02,1), loc=\"upper left\"); plt.tight_layout(); plt.show()\n",
        "\n",
        "plot_metric(\"test_RMSE\", \"Test RMSE vs iteration\")\n",
        "plot_metric(\"erank\",     \"Effective rank (erank) vs iteration\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6KyWmUsKv0w"
      },
      "outputs": [],
      "source": [
        "ml = df[df[\"file\"].str.contains(\"ML_\", na=False)]\n",
        "assert not ml.empty, \"No MovieLens rows parsed. Run Cell 6 first.\"\n",
        "\n",
        "#Extract λ from filename for labeling\n",
        "def lab(name):\n",
        "    return \"λ=1e-3\" if \"lam1e-3\" in name else \"λ=0\"\n",
        "\n",
        "def plot_ml(metric, title):\n",
        "    plt.figure(figsize=(6.6,4.4))\n",
        "    for key, g in ml.groupby(\"file\"):\n",
        "        g = g.sort_values(\"iteration\")\n",
        "        plt.plot(g[\"iteration\"], g[metric], \"--\", label=f\"Adam d=1, {lab(key)}\")\n",
        "    plt.xlabel(\"iteration\"); plt.ylabel(metric); plt.title(title)\n",
        "    plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "plot_ml(\"test_RMSE\", \"MovieLens: test_RMSE\")\n",
        "plot_ml(\"erank\",     \"MovieLens: erank\")\n",
        "\n",
        "#summary table\n",
        "last = (ml.sort_values([\"file\",\"iteration\"])\n",
        "          .groupby(\"file\").tail(1)\n",
        "          [[\"file\",\"iteration\",\"test_RMSE\",\"erank\",\"s1\",\"s5\"]])\n",
        "print(\"=== MovieLens last metrics ===\")\n",
        "print(last.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jR1bqAOeKx-W"
      },
      "outputs": [],
      "source": [
        "last_syn = (df[~df[\"file\"].str.contains(\"ML_\", na=False)]\n",
        "              .sort_values([\"optimizer\",\"depth\",\"iteration\"])\n",
        "              .groupby([\"optimizer\",\"depth\"]).tail(1)\n",
        "              [[\"optimizer\",\"depth\",\"iteration\",\"test_RMSE\",\"erank\",\"s1\",\"s5\"]])\n",
        "print(\"=== Last metrics (synthetic, per optimizer & depth) ===\")\n",
        "print(last_syn.to_string(index=False))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
